{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\programs\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "from string import punctuation\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pymorphy2\n",
    "import gensim\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def take_text(fin):\n",
    "    f = open(fin, 'r', encoding = 'utf-8')\n",
    "    twi = []\n",
    "    cont = []\n",
    "    l = f.readlines()\n",
    "    for i in l:\n",
    "        i = i.replace('\"\\n', '')\n",
    "        if i[0] == '\"':\n",
    "            lst = i[1:].split('\";\"')\n",
    "        else:\n",
    "            lst = i.split('\";\"')\n",
    "        if len(lst) == 12:\n",
    "            twi.append(lst)\n",
    "        elif cont == []:\n",
    "            cont += lst\n",
    "        elif '\\n' in cont[-1] and lst != []:\n",
    "            c = cont[-1]\n",
    "            cont = cont[:-1]\n",
    "            cont.append(c+lst[0])\n",
    "            cont += lst[1:]\n",
    "            if len(cont) == 12:\n",
    "                twi.append(cont)\n",
    "                cont = []\n",
    "    f.close()\n",
    "    \n",
    "    only_twits = []\n",
    "    for line in twi:\n",
    "        only_twits.append(line[3])\n",
    "    \n",
    "    return only_twits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spacing(text):\n",
    "    spaces = re.findall('[^\\\\w]((?:\\\\w ){3,}\\\\w)[ '+string.punctuation+'—–…“”«»'+']',text)\n",
    "    for elem in spaces:\n",
    "        text = text.replace(elem,elem.replace(' ',''))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(l):\n",
    "    l = re.sub(r\"((https?:\\/\\/|www)|\\w+\\.(\\w{2-3}))([\\w\\!#$&-;=\\?\\-\\[\\]~]|%[0-9a-fA-F]{2})+\", '', l) #убираем ссылки\n",
    "    l = re.sub(r\"(?:@\\w+)\", '', l)                                        # убираем пользователя\n",
    "    l = re.sub(r\"[\\w.+-]+@[\\w-]+\\.(?:[\\w-]\\.?)+[\\w-]\", '', l)             # убираем email\n",
    "    l = re.sub(r\"(?:I'm at .*? in .*?(?: w/ @[\\w])?|\\(@ .*?\\))\", '', l)   # убираем геолокации\n",
    "    l = l.replace('RT', '')                                              # убираем RT\n",
    "    exclude = string.punctuation + '0123456789' + u'—' + u'«»'\n",
    "    regex = re.compile('[%s]' % re.escape(exclude))\n",
    "    l = regex.sub(' ', l)\n",
    "    lower_up = [m.start() for m in re.finditer(r\"[a-zа-яё]{1}[A-ZА-ЯЁ]{1}\", l)]   # добавляем пробел между lower- и uppercase HiWorld => Hi World\n",
    "    for i in reversed(lower_up):\n",
    "        l = l[:i+1] + ' ' + l[i+1:]\n",
    "    l = re.sub(u'(\\w)\\\\1{2,}', u'\\\\1\\\\1', l)   # буквы больше двух раз подряд\n",
    "    l = spacing(l)                                # р а з р я д к а\n",
    "    l = l.lower()                                                         # уменьшаем регистр у всех букв\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm_tw(twits):\n",
    "    norm_twits = []\n",
    "    for i in range(len(twits)):\n",
    "        norm_twits.append(normalize(twits[i]))\n",
    "    return norm_twits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twits = take_text('positive.csv')\n",
    "neg_twits = take_text('negative.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twits = random.sample(twits, len(twits)//10)\n",
    "neg_twits = random.sample(neg_twits, len(neg_twits)//10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_twits = norm_tw(twits)\n",
    "neg_norm_twits = norm_tw(neg_twits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data1 = pd.DataFrame.from_dict({'text':norm_twits})\n",
    "data1['class'] = 1\n",
    "data2 = pd.DataFrame.from_dict({'text':neg_norm_twits})\n",
    "data2['class'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data1, data2])\n",
    "data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ты начинаешь злиться а я улыбаюсь я счастлива ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>но димон же зол на него  поэтому стоит увиде...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>вроде на улице зима  а до меня это еще не дохо...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>сел короче проверить мозги после нг  пробный е...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>место того чтоб учить  я слушаю музыку  класс</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class\n",
       "0  ты начинаешь злиться а я улыбаюсь я счастлива ...      1\n",
       "1    но димон же зол на него  поэтому стоит увиде...      1\n",
       "2  вроде на улице зима  а до меня это еще не дохо...      1\n",
       "3  сел короче проверить мозги после нг  пробный е...      0\n",
       "4    место того чтоб учить  я слушаю музыку  класс        0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save as csv\n",
    "\n",
    "data.to_csv('dataframe.csv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
