{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Опрос - https://goo.gl/forms/F9repCtzeP8av1uv1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Синтаксические и семантические парсеры\n",
    "* Парсер составляющих: http://tomato.banatao.berkeley.edu:8080/parser/parser.html\n",
    "* Парсеры зависимостей: http://nlp.stanford.edu:8080/corenlp/process и http://demo.ark.cs.cmu.edu/parse\n",
    "* Универсальные зависимости: http://universaldependencies.org/u/overview/syntax.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторная модель документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sanek\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "2017-02-02 06:48:33,658 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora\n",
    "documents = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",              \n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Проведем токенизацию, удалим одиночные и общеупотребительные слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    "         for document in documents]\n",
    "\n",
    "# remove words that appear only once\n",
    "from collections import defaultdict\n",
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "\n",
    "texts = [[token for token in text if frequency[token] > 1] for text in texts]\n",
    "\n",
    "from pprint import pprint  # pretty-printer\n",
    "pprint(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Теперь конвертируем документ в вектор, используя технику \"мешко слов\" (bow): (word_id, word_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:52:40,473 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2017-02-02 06:52:40,476 : INFO : built Dictionary(12 unique tokens: ['minors', 'system', 'eps', 'interface', 'trees']...) from 9 documents (total 29 corpus positions)\n",
      "2017-02-02 06:52:40,478 : INFO : saving Dictionary object under deerwester.dict, separately None\n",
      "2017-02-02 06:52:40,522 : INFO : saved deerwester.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['minors', 'system', 'eps', 'interface', 'trees']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('deerwester.dict')  # store the dictionary, for future reference\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'minors': 11, 'system': 5, 'eps': 8, 'interface': 2, 'trees': 9, 'time': 3, 'user': 4, 'computer': 1, 'response': 7, 'survey': 6, 'graph': 10, 'human': 0}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Посмотрим векторное представление предлдожения по нашему словарю"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)  # the word \"interaction\" does not appear in the dictionary and is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 06:57:55,767 : INFO : storing corpus in Matrix Market format to deerwester.mm\n",
      "2017-02-02 06:57:55,770 : INFO : saving sparse matrix to deerwester.mm\n",
      "2017-02-02 06:57:55,772 : INFO : PROGRESS: saving document #0\n",
      "2017-02-02 06:57:55,774 : INFO : saved 9x12 matrix, density=25.926% (28/108)\n",
      "2017-02-02 06:57:55,780 : INFO : saving MmCorpus index to deerwester.mm.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1)]\n",
      "[(1, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "[(2, 1), (4, 1), (5, 1), (8, 1)]\n",
      "[(0, 1), (5, 2), (8, 1)]\n",
      "[(3, 1), (4, 1), (7, 1)]\n",
      "[(9, 1)]\n",
      "[(9, 1), (10, 1)]\n",
      "[(9, 1), (10, 1), (11, 1)]\n",
      "[(6, 1), (10, 1), (11, 1)]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('deerwester.mm', corpus)  # store to disk, for later use\n",
    "for c in corpus:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Поиск ключевых слов и похожих документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:04:50,532 : INFO : loading Dictionary object from deerwester.dict\n",
      "2017-02-02 07:04:50,535 : INFO : loaded deerwester.dict\n",
      "2017-02-02 07:04:50,538 : INFO : loaded corpus index from deerwester.mm.index\n",
      "2017-02-02 07:04:50,539 : INFO : initializing corpus reader from deerwester.mm\n",
      "2017-02-02 07:04:50,541 : INFO : accepted corpus with 9 documents, 12 features, 28 non-zero entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(9 documents, 12 features, 28 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary.load('deerwester.dict')\n",
    "corpus = corpora.MmCorpus('deerwester.mm') # comes from the first tutorial, \"From strings to vectors\"\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализирум нашу модель перехода от одного векторного представления в другое"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:08:33,929 : INFO : collecting document frequencies\n",
      "2017-02-02 07:08:33,932 : INFO : PROGRESS: processing document #0\n",
      "2017-02-02 07:08:33,934 : INFO : calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Проверим, как она работает для одного документа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.7071067811865476), (1, 0.7071067811865476)]\n"
     ]
    }
   ],
   "source": [
    "doc_bow = [(0, 1), (1, 1)]\n",
    "print(tfidf[doc_bow]) # step 2 -- use the model to transform vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "и для всего корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.5773502691896257), (1, 0.5773502691896257), (2, 0.5773502691896257)]\n",
      "[(1, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.3244870206138555), (5, 0.3244870206138555), (6, 0.44424552527467476), (7, 0.44424552527467476)]\n",
      "[(2, 0.5710059809418182), (4, 0.4170757362022777), (5, 0.4170757362022777), (8, 0.5710059809418182)]\n",
      "[(0, 0.49182558987264147), (5, 0.7184811607083769), (8, 0.49182558987264147)]\n",
      "[(3, 0.6282580468670046), (4, 0.45889394536615247), (7, 0.6282580468670046)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.7071067811865475), (10, 0.7071067811865475)]\n",
      "[(9, 0.5080429008916749), (10, 0.5080429008916749), (11, 0.695546419520037)]\n",
      "[(6, 0.6282580468670046), (10, 0.45889394536615247), (11, 0.6282580468670046)]\n"
     ]
    }
   ],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "for doc in corpus_tfidf:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Мы можем составлять цепочки моделей. Например, добавим латетную семантическую модель, переводящую tf-idf в 2-мерное пространство"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:12:21,301 : INFO : using serial LSI version on this node\n",
      "2017-02-02 07:12:21,304 : INFO : updating model with new documents\n",
      "2017-02-02 07:12:21,307 : INFO : preparing a new chunk of documents\n",
      "2017-02-02 07:12:21,310 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-02 07:12:21,313 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2017-02-02 07:12:21,315 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2017-02-02 07:12:21,332 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2017-02-02 07:12:21,335 : INFO : computing the final decomposition\n",
      "2017-02-02 07:12:21,337 : INFO : keeping 2 factors (discarding 47.565% of energy spectrum)\n",
      "2017-02-02 07:12:21,340 : INFO : processed documents up to #9\n",
      "2017-02-02 07:12:21,344 : INFO : topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"response\" + 0.060*\"time\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
      "2017-02-02 07:12:21,346 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2) # initialize an LSI transformation\n",
    "corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:14:43,876 : INFO : topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"response\" + 0.060*\"time\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
      "2017-02-02 07:14:43,879 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"response\" + 0.060*\"time\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
       " (1,\n",
       "  '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"response\" + -0.320*\"time\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Мы можем посмотреть распределение наших документов по этим двум темам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.066007833960905274), (1, -0.52007033063618358)]\n",
      "[(0, 0.1966759285914276), (1, -0.76095631677000419)]\n",
      "[(0, 0.089926399724465866), (1, -0.72418606267524999)]\n",
      "[(0, 0.075858476521782917), (1, -0.63205515860034178)]\n",
      "[(0, 0.10150299184980294), (1, -0.57373084830029597)]\n",
      "[(0, 0.70321089393782998), (1, 0.16115180214025987)]\n",
      "[(0, 0.87747876731198193), (1, 0.16758906864659656)]\n",
      "[(0, 0.90986246868185683), (1, 0.14086553628719287)]\n",
      "[(0, 0.61658253505692828), (1, -0.053929075663891803)]\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus_lsi: # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:18:43,632 : INFO : saving Projection object under model.lsi.projection, separately None\n",
      "2017-02-02 07:18:43,639 : INFO : saved model.lsi.projection\n",
      "2017-02-02 07:18:43,641 : INFO : saving LsiModel object under model.lsi, separately None\n",
      "2017-02-02 07:18:43,642 : INFO : not storing attribute projection\n",
      "2017-02-02 07:18:43,644 : INFO : not storing attribute dispatcher\n",
      "2017-02-02 07:18:43,651 : INFO : saved model.lsi\n",
      "2017-02-02 07:18:43,652 : INFO : loading LsiModel object from model.lsi\n",
      "2017-02-02 07:18:43,655 : INFO : loading id2word recursively from model.lsi.id2word.* with mmap=None\n",
      "2017-02-02 07:18:43,656 : INFO : setting ignored attribute projection to None\n",
      "2017-02-02 07:18:43,657 : INFO : setting ignored attribute dispatcher to None\n",
      "2017-02-02 07:18:43,659 : INFO : loaded model.lsi\n",
      "2017-02-02 07:18:43,661 : INFO : loading LsiModel object from model.lsi.projection\n",
      "2017-02-02 07:18:43,664 : INFO : loaded model.lsi.projection\n"
     ]
    }
   ],
   "source": [
    "lsi.save('model.lsi') # same for tfidf, lda, ...\n",
    "lsi = models.LsiModel.load('model.lsi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Другие векторные модели:\n",
    "* [Random Projections, RP](http://www.cis.hut.fi/ella/publications/randproj_kdd.pdf): models.RpModel(tfidf_corpus, num_topics=500)\n",
    "* [Latent Dirichlet Allocation, LDA](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation): models.LdaModel(corpus, id2word=dictionary, num_topics=100)\n",
    "* [Hierarchical Dirichlet Process, HDP](http://jmlr.csail.mit.edu/proceedings/papers/v15/wang11a/wang11a.pdf): models.HdpModel(corpus, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Поиск похожих документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:25:38,018 : INFO : loading Dictionary object from deerwester.dict\n",
      "2017-02-02 07:25:38,021 : INFO : loaded deerwester.dict\n",
      "2017-02-02 07:25:38,023 : INFO : loaded corpus index from deerwester.mm.index\n",
      "2017-02-02 07:25:38,025 : INFO : initializing corpus reader from deerwester.mm\n",
      "2017-02-02 07:25:38,028 : INFO : accepted corpus with 9 documents, 12 features, 28 non-zero entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MmCorpus(9 documents, 12 features, 28 non-zero entries)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary.load('deerwester.dict')\n",
    "corpus = corpora.MmCorpus('deerwester.mm') # comes from the first tutorial, \"From strings to vectors\"\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:25:46,236 : INFO : using serial LSI version on this node\n",
      "2017-02-02 07:25:46,238 : INFO : updating model with new documents\n",
      "2017-02-02 07:25:46,241 : INFO : preparing a new chunk of documents\n",
      "2017-02-02 07:25:46,243 : INFO : using 100 extra samples and 2 power iterations\n",
      "2017-02-02 07:25:46,244 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2017-02-02 07:25:46,246 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2017-02-02 07:25:46,249 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2017-02-02 07:25:46,251 : INFO : computing the final decomposition\n",
      "2017-02-02 07:25:46,253 : INFO : keeping 2 factors (discarding 43.156% of energy spectrum)\n",
      "2017-02-02 07:25:46,255 : INFO : processed documents up to #9\n",
      "2017-02-02 07:25:46,257 : INFO : topic #0(3.341): 0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"time\" + 0.265*\"response\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"\n",
      "2017-02-02 07:25:46,259 : INFO : topic #1(2.542): -0.623*\"graph\" + -0.490*\"trees\" + -0.451*\"minors\" + -0.274*\"survey\" + 0.167*\"system\" + 0.141*\"eps\" + 0.113*\"human\" + -0.107*\"time\" + -0.107*\"response\" + 0.072*\"interface\"\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Пусть пользователь ввел запрос \"Human computer interaction\". Мы хотим оценить релевантность наших документов этому запросу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.46182100453271613), (1, 0.070027665279000006)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow] # convert the query to LSI space\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь наша задача подготовить наши документы к анализу релевантности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:30:38,707 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2017-02-02 07:30:38,711 : INFO : creating matrix with 9 documents and 2 features\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus]) # transform corpus to LSI space and index it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFkCAYAAAANC2PrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ9vMzKxLOLTNzMy6xP8H5yK7PimAjRcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e35d2c9470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pylab import pcolor, show, colorbar, xticks, yticks\n",
    "%matplotlib inline\n",
    "\n",
    "pcolor(index[lsi[corpus]])\n",
    "colorbar()\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:33:17,196 : INFO : saving MatrixSimilarity object under deerwester.index, separately None\n",
      "2017-02-02 07:33:17,204 : INFO : saved deerwester.index\n",
      "2017-02-02 07:33:17,206 : INFO : loading MatrixSimilarity object from deerwester.index\n",
      "2017-02-02 07:33:17,208 : INFO : loaded deerwester.index\n"
     ]
    }
   ],
   "source": [
    "index.save('deerwester.index')\n",
    "index = similarities.MatrixSimilarity.load('deerwester.index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Теперь оценим похожесть нашего запроса и документов из корпуса, используя косинусную меру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.99809301), (1, 0.93748635), (2, 0.99844527), (3, 0.9865886), (4, 0.90755945), (5, -0.12416792), (6, -0.10639259), (7, -0.098794639), (8, 0.050041765)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi] # perform a similarity query against the corpus\n",
    "print(list(enumerate(sims))) # print (document_number, document_similarity) 2-tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, 0.99844527), (0, 0.99809301), (3, 0.9865886), (1, 0.93748635), (4, 0.90755945), (8, 0.050041765), (7, -0.098794639), (6, -0.10639259), (5, -0.12416792)]\n"
     ]
    }
   ],
   "source": [
    "sims = sorted(enumerate(sims), key=lambda item: -item[1])\n",
    "print(sims) # print sorted (document number, similarity score) 2-tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Векторное представление слов - word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Цель векторно представления слов - находить отношения между словами и оценивать их семантику: vec(“king”) – vec(“man”) + vec(“woman”) =~ vec(“queen”) или vec(“Montreal Canadiens”) – vec(“Montreal”) + vec(“Toronto”) =~ vec(“Toronto Maple Leafs”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:44:06,808 : INFO : collecting all words and their counts\n",
      "2017-02-02 07:44:06,811 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-02-02 07:44:06,813 : INFO : collected 3 word types from a corpus of 4 raw words and 2 sentences\n",
      "2017-02-02 07:44:06,814 : INFO : Loading a fresh vocabulary\n",
      "2017-02-02 07:44:06,816 : INFO : min_count=1 retains 3 unique words (100% of original 3, drops 0)\n",
      "2017-02-02 07:44:06,818 : INFO : min_count=1 leaves 4 word corpus (100% of original 4, drops 0)\n",
      "2017-02-02 07:44:06,819 : INFO : deleting the raw counts dictionary of 3 items\n",
      "2017-02-02 07:44:06,821 : INFO : sample=0.001 downsamples 3 most-common words\n",
      "2017-02-02 07:44:06,823 : INFO : downsampling leaves estimated 0 word corpus (5.7% of prior 4)\n",
      "2017-02-02 07:44:06,825 : INFO : estimated required memory for 3 words and 100 dimensions: 3900 bytes\n",
      "2017-02-02 07:44:06,837 : INFO : resetting layer weights\n",
      "2017-02-02 07:44:06,839 : INFO : training model with 3 workers on 3 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-02-02 07:44:06,840 : INFO : expecting 2 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-02-02 07:44:06,848 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-02-02 07:44:06,850 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-02-02 07:44:06,852 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-02-02 07:44:06,853 : INFO : training on 20 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2017-02-02 07:44:06,855 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "sentences = [['first', 'sentence'], ['second', 'sentence']]\n",
    "# train word2vec on the two sentences\n",
    "model = models.Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=3, size=100, alpha=0.025)\n",
      "{'second': <gensim.models.word2vec.Vocab object at 0x000001E3625E40F0>, 'first': <gensim.models.word2vec.Vocab object at 0x000001E3625D63C8>, 'sentence': <gensim.models.word2vec.Vocab object at 0x000001E362658F28>}\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Возьмем корпус побольше и создадим свой потоковый источник предложений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyText object at 0x000001E36258BCC0>\n"
     ]
    }
   ],
   "source": [
    "class MyText(object):\n",
    "    def __iter__(self):\n",
    "        for line in open('../data/lee_background.cor'):\n",
    "            # assume there's one document per line, tokens separated by whitespace\n",
    "            yield line.lower().split()\n",
    "\n",
    "sentences = MyText()\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Результат обучения модели - матрица размера  #vocabulary x #size. У модели word2vec есть несколько настроек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:50:52,473 : INFO : collecting all words and their counts\n",
      "2017-02-02 07:50:52,476 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-02-02 07:50:52,508 : INFO : collected 10186 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2017-02-02 07:50:52,509 : INFO : Loading a fresh vocabulary\n",
      "2017-02-02 07:50:52,520 : INFO : min_count=10 retains 806 unique words (7% of original 10186, drops 9380)\n",
      "2017-02-02 07:50:52,521 : INFO : min_count=10 leaves 40964 word corpus (68% of original 59890, drops 18926)\n",
      "2017-02-02 07:50:52,527 : INFO : deleting the raw counts dictionary of 10186 items\n",
      "2017-02-02 07:50:52,529 : INFO : sample=0.001 downsamples 54 most-common words\n",
      "2017-02-02 07:50:52,533 : INFO : downsampling leaves estimated 26224 word corpus (64.0% of prior 40964)\n",
      "2017-02-02 07:50:52,539 : INFO : estimated required memory for 806 words and 100 dimensions: 1047800 bytes\n",
      "2017-02-02 07:50:52,548 : INFO : resetting layer weights\n",
      "2017-02-02 07:50:52,576 : INFO : training model with 3 workers on 806 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-02-02 07:50:52,578 : INFO : expecting 300 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-02-02 07:50:52,790 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-02-02 07:50:52,794 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-02-02 07:50:52,801 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-02-02 07:50:52,804 : INFO : training on 299450 raw words (130961 effective words) took 0.2s, 636436 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# default value of min_count=5\n",
    "model = models.Word2Vec(sentences, min_count=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:51:52,820 : INFO : collecting all words and their counts\n",
      "2017-02-02 07:51:52,823 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-02-02 07:51:52,849 : INFO : collected 10186 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2017-02-02 07:51:52,851 : INFO : Loading a fresh vocabulary\n",
      "2017-02-02 07:51:52,861 : INFO : min_count=5 retains 1723 unique words (16% of original 10186, drops 8463)\n",
      "2017-02-02 07:51:52,864 : INFO : min_count=5 leaves 46858 word corpus (78% of original 59890, drops 13032)\n",
      "2017-02-02 07:51:52,878 : INFO : deleting the raw counts dictionary of 10186 items\n",
      "2017-02-02 07:51:52,887 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2017-02-02 07:51:52,889 : INFO : downsampling leaves estimated 32849 word corpus (70.1% of prior 46858)\n",
      "2017-02-02 07:51:52,891 : INFO : estimated required memory for 1723 words and 200 dimensions: 3618300 bytes\n",
      "2017-02-02 07:51:52,904 : INFO : resetting layer weights\n",
      "2017-02-02 07:51:52,953 : INFO : training model with 3 workers on 1723 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-02-02 07:51:52,955 : INFO : expecting 300 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-02-02 07:51:53,255 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-02-02 07:51:53,259 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-02-02 07:51:53,271 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-02-02 07:51:53,272 : INFO : training on 299450 raw words (164333 effective words) took 0.3s, 526490 effective words/s\n"
     ]
    }
   ],
   "source": [
    "# default value of size=100\n",
    "model = models.Word2Vec(sentences, size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 07:52:20,489 : INFO : collecting all words and their counts\n",
      "2017-02-02 07:52:20,492 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-02-02 07:52:20,517 : INFO : collected 10186 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2017-02-02 07:52:20,518 : INFO : Loading a fresh vocabulary\n",
      "2017-02-02 07:52:20,529 : INFO : min_count=5 retains 1723 unique words (16% of original 10186, drops 8463)\n",
      "2017-02-02 07:52:20,530 : INFO : min_count=5 leaves 46858 word corpus (78% of original 59890, drops 13032)\n",
      "2017-02-02 07:52:20,539 : INFO : deleting the raw counts dictionary of 10186 items\n",
      "2017-02-02 07:52:20,541 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2017-02-02 07:52:20,543 : INFO : downsampling leaves estimated 32849 word corpus (70.1% of prior 46858)\n",
      "2017-02-02 07:52:20,545 : INFO : estimated required memory for 1723 words and 100 dimensions: 2239900 bytes\n",
      "2017-02-02 07:52:20,559 : INFO : resetting layer weights\n",
      "2017-02-02 07:52:20,618 : INFO : training model with 4 workers on 1723 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-02-02 07:52:20,621 : INFO : expecting 300 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-02-02 07:52:20,844 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-02-02 07:52:20,847 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-02-02 07:52:20,850 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-02-02 07:52:20,861 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-02-02 07:52:20,863 : INFO : training on 299450 raw words (164467 effective words) took 0.2s, 693713 effective words/s\n",
      "2017-02-02 07:52:20,866 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "# default value of workers=3 (tutorial says 1...)\n",
    "model = models.Word2Vec(sentences, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:29:29,221 : INFO : collecting all words and their counts\n",
      "2017-02-02 08:29:29,225 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-02-02 08:29:29,250 : INFO : collected 10186 word types from a corpus of 59890 raw words and 300 sentences\n",
      "2017-02-02 08:29:29,251 : INFO : Loading a fresh vocabulary\n",
      "2017-02-02 08:29:29,265 : INFO : min_count=5 retains 1723 unique words (16% of original 10186, drops 8463)\n",
      "2017-02-02 08:29:29,269 : INFO : min_count=5 leaves 46858 word corpus (78% of original 59890, drops 13032)\n",
      "2017-02-02 08:29:29,283 : INFO : deleting the raw counts dictionary of 10186 items\n",
      "2017-02-02 08:29:29,287 : INFO : sample=0.001 downsamples 49 most-common words\n",
      "2017-02-02 08:29:29,290 : INFO : downsampling leaves estimated 32849 word corpus (70.1% of prior 46858)\n",
      "2017-02-02 08:29:29,295 : INFO : estimated required memory for 1723 words and 100 dimensions: 2239900 bytes\n",
      "2017-02-02 08:29:29,310 : INFO : resetting layer weights\n",
      "2017-02-02 08:29:29,349 : INFO : training model with 3 workers on 1723 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-02-02 08:29:29,352 : INFO : expecting 300 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-02-02 08:29:29,630 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-02-02 08:29:29,638 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-02-02 08:29:29,640 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-02-02 08:29:29,643 : INFO : training on 299450 raw words (164324 effective words) took 0.3s, 583401 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = models.Word2Vec(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы можем как постепенно дообучать модель (онлайн обучение), так и зафиксировать ее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:29:35,440 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2vec поддерживает ряд втроенных функций по оценке схожести"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('growing', 0.9911920428276062)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['human', 'crime'], negative=['party'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"input is lunch he sentence cat\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.998945122757\n",
      "0.995429865781\n"
     ]
    }
   ],
   "source": [
    "print(model.similarity('human', 'party'))\n",
    "print(model.similarity('tree', 'murder'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02571549,  0.05654283,  0.08735893,  0.06042101,  0.1080929 ,\n",
       "       -0.02331162, -0.0018254 ,  0.06333245, -0.05215555,  0.06805436,\n",
       "       -0.06000465, -0.24123077, -0.1084304 ,  0.11672158, -0.14518464,\n",
       "       -0.10641909,  0.20966332, -0.04578859, -0.00279448, -0.03958187,\n",
       "        0.02091216,  0.19292636, -0.02010854, -0.01896548, -0.01460866,\n",
       "       -0.09219701, -0.00053441, -0.02324938, -0.14263582,  0.1107691 ,\n",
       "        0.13305394,  0.05190931, -0.02660829,  0.02601514,  0.02034386,\n",
       "       -0.09105876,  0.0669838 , -0.22144325, -0.08958331, -0.13569823,\n",
       "       -0.00048439, -0.01253671,  0.03806499,  0.0325041 ,  0.06020157,\n",
       "        0.30387774, -0.0797781 , -0.0440162 ,  0.19684649,  0.04818842,\n",
       "       -0.00277689, -0.10702567,  0.03451814,  0.02370303,  0.03958154,\n",
       "       -0.01678191,  0.09321268, -0.15446551,  0.02200461,  0.02116641,\n",
       "       -0.11456019,  0.01065565, -0.02430117,  0.03892392, -0.02115884,\n",
       "        0.13492824, -0.00146681,  0.01885894, -0.03583477, -0.05408842,\n",
       "        0.06038593,  0.19429472, -0.05793711, -0.07214473, -0.15695812,\n",
       "       -0.04931074, -0.01828611, -0.1219849 ,  0.16696458, -0.08851513,\n",
       "        0.13550729, -0.05818044,  0.05030402,  0.13919841, -0.11865974,\n",
       "       -0.15363239,  0.20783414,  0.03065231, -0.01073679, -0.26751599,\n",
       "       -0.00278449, -0.02087366,  0.05897195,  0.01871619, -0.09126092,\n",
       "       -0.01706196,  0.01747377, -0.13653006,  0.05182511, -0.09262434], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['human']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('muslim', 0.9961795806884766),\n",
       " ('warned', 0.9960293769836426),\n",
       " ('abuse', 0.9959511160850525),\n",
       " ('week', 0.9958263635635376),\n",
       " ('minister,', 0.9958088397979736)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['park', 'questions'], negative=['reduce'], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.accuracy('../data/questions-words.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Мы можем в качестве \"слов\" использовать биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-02-02 08:10:31,670 : INFO : collecting all words and their counts\n",
      "2017-02-02 08:10:31,674 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "2017-02-02 08:10:31,862 : INFO : collected 48026 word types from a corpus of 59590 words (unigram + bigrams) and 300 sentences\n",
      "2017-02-02 08:10:31,864 : INFO : using 48026 counts as vocab in Phrases<0 vocab, min_count=5, threshold=10.0, max_vocab_size=40000000>\n",
      "C:\\Users\\sanek\\Anaconda3\\lib\\site-packages\\gensim\\models\\phrases.py:248: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n",
      "2017-02-02 08:10:31,910 : INFO : collecting all words and their counts\n",
      "2017-02-02 08:10:31,916 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-02-02 08:10:32,219 : INFO : collected 10440 word types from a corpus of 56279 raw words and 300 sentences\n",
      "2017-02-02 08:10:32,220 : INFO : Loading a fresh vocabulary\n",
      "2017-02-02 08:10:32,235 : INFO : min_count=5 retains 1892 unique words (18% of original 10440, drops 8548)\n",
      "2017-02-02 08:10:32,237 : INFO : min_count=5 leaves 43028 word corpus (76% of original 56279, drops 13251)\n",
      "2017-02-02 08:10:32,249 : INFO : deleting the raw counts dictionary of 10440 items\n",
      "2017-02-02 08:10:32,253 : INFO : sample=0.001 downsamples 43 most-common words\n",
      "2017-02-02 08:10:32,257 : INFO : downsampling leaves estimated 31104 word corpus (72.3% of prior 43028)\n",
      "2017-02-02 08:10:32,259 : INFO : estimated required memory for 1892 words and 100 dimensions: 2459600 bytes\n",
      "2017-02-02 08:10:32,278 : INFO : resetting layer weights\n",
      "2017-02-02 08:10:32,321 : INFO : training model with 3 workers on 1892 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2017-02-02 08:10:32,323 : INFO : expecting 300 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-02-02 08:10:33,386 : INFO : PROGRESS: at 70.40% examples, 104108 words/s, in_qsize 0, out_qsize 0\n",
      "2017-02-02 08:10:33,813 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-02-02 08:10:33,818 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-02-02 08:10:33,820 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-02-02 08:10:33,822 : INFO : training on 281395 raw words (155540 effective words) took 1.5s, 104251 effective words/s\n",
      "2017-02-02 08:10:33,825 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "bigram_transformer = models.Phrases(sentences)\n",
    "model = models.Word2Vec(bigram_transformer[sentences], size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Для дальнейшего изучения\n",
    "* Подробнее про Dictionary и doc2bow https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/Corpora_and_Vector_Spaces.ipynb\n",
    "* Latent semantic analysis/indexing как SVD  http://nbviewer.jupyter.org/url/cslu.ohsu.edu/~gormanky/courses/CS662/Notebooks/CS-562-662-latent-semantic-analyis.ipynb \n",
    "* LSA и LDA в gensim: https://radimrehurek.com/gensim/wiki.html \n",
    "* Дистрибутивные модели в PyDSM https://github.com/jimmycallin/notebooks/blob/master/PyDSM%20Meetup%20Presentation.ipynb \n",
    "* Дистрибутивные модели для русского: http://ling.go.mail.ru/dsm/ru/ (можно посмотреть разные примеры и разные функции на сайте, например, сексизм в “похожих словах” интеллектуал VS интеллектуалка, ассоциации (у меня нашлась забавная волосы : шампунь = зуб : паста) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
