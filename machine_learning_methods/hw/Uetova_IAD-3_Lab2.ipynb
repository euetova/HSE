{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Срок сдачи:** 25 октября 2016, 23:59 <br\\>\n",
    "\n",
    "При отправлении ДЗ на почту указывайте **фамилию** в названии файла, и тему письма оформляйте в следующем формате: <br\\>\n",
    "** [Maйнор 2016] ДЗ2 **<br\\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочтите статью [\"USING\tDATA\tMINING\tTO\tPREDICT\tSECONDARY SCHOOL\tSTUDENT\tALCOHOL\tCONSUMPTION\"](https://www.dropbox.com/s/054unjn4bfo0khj/STUDENT%20ALCOHOL%20CONSUMPTION.pdf?dl=0), загрузите [датасет](https://archive.ics.uci.edu/ml/datasets/STUDENT+ALCOHOL+CONSUMPTION#) и выполните следующие задания:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mat = pd.read_csv('student-mat.csv', sep = ';')\n",
    "por = pd.read_csv('student-por.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Работа с данными (4 балла)\n",
    "- Приведите описание признаков датасета на русском языке с указанием типа данных (1 балла)\n",
    "- Предобработка данных (3)\n",
    "    - Проверьте наличие пропусков. В случае наличия пропусков заполните их медианными значениями (1)\n",
    "    - Подсчитайте количество записей, у которых признак Medu имеет значение \"4\" (1)\n",
    "    - Преобразуйте все номинальные признаки в несколько признаков с бинарным значение (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. school - название школы студента - бинарный признак 'GP' или 'MS'\n",
    "2. sex - пол студента - бинарный признак 'F'(женский) или 'M'(мужской)\n",
    "3. age - возраст студента - вещественный признак - от 15 до 22 лет\n",
    "4. address - тип населенного пункта - бинарный признак 'U'(город) или 'R'(село)\n",
    "5. famsize - размер семьби студента - бинарный признак 'LE3'(не больше 3 членов семьи) или 'GT3'(больше трех)\n",
    "6. Pstatus - живут ли родители вместе - бинарный 'T'(живут вместе) или 'A' (живут отдельно)\n",
    "7. Medu - образование матери и \n",
    "8. Fedu - образование отца - вещественный: 0 - нет образования, 1 - начальное общее образование (4 класса), 2 - обсновное общее образование (9 классов), 3 - среднее общее образование (11 классов), 4 - высшее образование \n",
    "9. Mjob - работа матери и \n",
    "10. Fjob - работа отца - категориальный признак:'teacher'(учитель), 'health'(мед.работник), 'services' (работник гос.служб), 'at_home'(сидит дома), 'other'(другое) \n",
    "11. reason - причина выбора школы - категориальный: 'home' (близко к дому), 'reputation' (престиж школы), 'course' (программа школы), 'other'(другое) \n",
    "12. guardian - попечитель студента - категориальный: 'mother'(мама), 'father'(папа), 'other'(другое)\n",
    "13. traveltime - время от дома до школы - вещественный: 1 - < 15 минут, 2 - от 15 дo 30 минут, 3 - от 0,5 до 1 часа, 4 - > 1 часа \n",
    "14. studytime - время учебы в неделю - вущуственный: 1 - < 2 часов, 2 - от 2 дo 5 часов, 3 - от 5 до 10 часов, 4 - > 10  \n",
    "15. failures - количество уроков, по которым \"неуд\" - вещественный: 1 - 1 неуд, 2 - 2 неуд, 3 - 3 неуд, 4 - больше 3 неуд\n",
    "16. schoolsup - стипендия - бинарный 'yes' или 'no'\n",
    "17. famsup - материальная помощь - бинарный 'yes' или 'no' \n",
    "18. paid - дополнительные платные занятия в рамках курса (математики или португальского) - бинарный 'yes' или 'no' \n",
    "19. activities - внеклассные занятия - бинарный 'yes' или 'no' \n",
    "20. nursery - ходил ли студент в дет.сад - бинарный 'yes' или 'no' \n",
    "21. higher - хочет ли студент получать высшее образование - бинарный 'yes' или 'no'\n",
    "22. internet - есть ли доступ к интернету дома - бинарный 'yes' или 'no'\n",
    "23. romantic - есть ли парень/девушка - бинарный 'yes' или 'no' \n",
    "24. famrel - отношения в семье - вещественный: от 1 - очень плохие до 5 - превосходные\n",
    "25. freetime - свободное время после школы - вещественный: от 1 - очень мало до 5 - очень много\n",
    "26. goout - встречи с друзьями - вещественный: от 1 - очень мало до 5 - очень много\n",
    "27. Dalc - потребление алкоголя в будни - вещественный: от 1 - очень мало до 5 - очень много\n",
    "28. Walc - потребление алкоголя в выходные - вещественный: от 1 - очень мало до 5 - очень много \n",
    "29. health - текущее состояние здоровья - вещественный: от 1 - очень плохое до 5 - очень хорошее\n",
    "30. absences - количество пропущенных дней - вещественный: от 0 дo 93 \n",
    "31. G1 - оценка за первый год - вещественный: от 0 дo 20 \n",
    "31. G2 - оценка за второй год - вещественный: от 0 дo 20  \n",
    "32. G3 - итоговая отценка - вещественный: от 0 дo 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Сначала мы создаем столбец alc для каждого датасета по формуле из статьи\n",
    "\n",
    "dsets = [mat, por]\n",
    "\n",
    "for d in dsets:\n",
    "    walc = d['Walc']\n",
    "    dalc = d['Dalc']\n",
    "    d['alc'] = 0\n",
    "    #d = d.drop(['Walc', 'Dalc'], axis=1) #удаляем столбцы Walc и Dalc, так как они лин.зависимы от alc\n",
    "    for i in range(len(d)):\n",
    "        if (2*walc[i] + 5*dalc[i])/7 >= 3:\n",
    "            d.loc[i, 'alc'] = 1\n",
    "            \n",
    "por = por.drop(['Walc', 'Dalc'], axis=1) #почему-то не работает в цикле\n",
    "mat = mat.drop(['Walc', 'Dalc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>romantic</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "      <th>alc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other ...   \n",
       "\n",
       "  romantic famrel  freetime  goout  health absences  G1  G2  G3 alc  \n",
       "0       no      4         3      4       3        6   5   6   6   0  \n",
       "1       no      5         3      3       3        4   5   5   6   0  \n",
       "2       no      4         3      2       3       10   7   8  10   0  \n",
       "3      yes      3         2      2       5        2  15  14  15   0  \n",
       "4       no      4         3      2       5        4   6  10  10   0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# параметр absence из вещественного признака в бинарный согласно статье\n",
    "# в статье и в презентации с сайта https://www.researchgate.net/publication/296695210_STUDENT_ALCOHOL_CONSUMPTION_presentation\n",
    "# разделение на 2 класса противоположны. Мне кажется, разделение в презентации логичнее, поэтому беру его\n",
    "\n",
    "for d in [mat, por]:   # почему-то не работает с dsets\n",
    "    for i in range(len(d)):\n",
    "        if d['absences'][i] > 10:\n",
    "            d.loc[i, 'absences'] = 1\n",
    "        else:\n",
    "            d.loc[i, 'absences'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# объединяем датасеты:\n",
    "\n",
    "df = pd.merge(mat, por, on=[\"school\",\"sex\",\"age\",\"address\",\"famsize\",\"Pstatus\",\"Medu\",\"Fedu\",\"Mjob\",\"Fjob\",\"reason\",\"nursery\",\"internet\"], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>romantic_y</th>\n",
       "      <th>famrel_y</th>\n",
       "      <th>freetime_y</th>\n",
       "      <th>goout_y</th>\n",
       "      <th>health_y</th>\n",
       "      <th>absences_y</th>\n",
       "      <th>G1_y</th>\n",
       "      <th>G2_y</th>\n",
       "      <th>G3_y</th>\n",
       "      <th>alc_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
       "\n",
       "   ...  romantic_y famrel_y  freetime_y  goout_y  health_y absences_y  G1_y  \\\n",
       "0  ...          no      4.0         3.0      4.0       3.0        0.0   0.0   \n",
       "1  ...          no      5.0         3.0      3.0       3.0        0.0   9.0   \n",
       "2  ...          no      4.0         3.0      2.0       3.0        0.0  12.0   \n",
       "3  ...         yes      3.0         2.0      2.0       5.0        0.0  14.0   \n",
       "4  ...          no      4.0         3.0      2.0       5.0        0.0  11.0   \n",
       "\n",
       "   G2_y  G3_y alc_y  \n",
       "0  11.0  11.0   0.0  \n",
       "1  11.0  11.0   0.0  \n",
       "2  13.0  12.0   0.0  \n",
       "3  14.0  14.0   0.0  \n",
       "4  13.0  13.0   0.0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5700"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Проверка наличия пропусков\n",
    "\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# заполнение пропусков значениями\n",
    "# часть пропущенных значений не имеет смысла заполнять медианными значениями, так как они не зависят от предмета,\n",
    "# например, 'guardian' и 'romantic', их я заполню информацией из соответствующей колонки с другим индексом.\n",
    "# То есть, например, колонку 'guardian_y' я заполню информацией из 'guardian_x'\n",
    "\n",
    "same_inf = ['guardian', 'traveltime', 'studytime', 'schoolsup', 'famsup', 'activities', 'higher', 'romantic',\n",
    "            'famrel', 'freetime', 'goout', 'alc', 'health']         #индексы столбцов, не зависящих от изучаемого предмета\n",
    "\n",
    "#mdn_inf = ['failures', 'paid', 'absences', 'G1', 'G2', 'G3']  #индексы столбцов, зависящих от предмета\n",
    "\n",
    "for i in same_inf:\n",
    "    for j in range(len(df)):\n",
    "        if pd.isnull(df[i+'_x'][j]):\n",
    "            df.loc[j, i+'_x'] = df[i+'_y'][j]\n",
    "        elif pd.isnull(df[i+'_y'][j]):\n",
    "            df.loc[j, i+'_y'] = df[i+'_x'][j]\n",
    "\n",
    "df = df.fillna(df.median()) # заполняем столбцы вещественных признаков медианными значениями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     223\n",
       "yes    184\n",
       "Name: paid_x, dtype: int64"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# paid бинарный признак, поэтому я его заполнила рандомными 0 и 1 с вероятностями\n",
    "\n",
    "df['paid_x'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     618\n",
       "yes     39\n",
       "Name: paid_y, dtype: int64"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['paid_y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# в 'paid_x' n:y = 11:9, в 'paid_y' n:y = 19:1\n",
    "\n",
    "for j in range(len(df)):\n",
    "    if pd.isnull(df['paid_x'][j]):\n",
    "        df.loc[j, 'paid_x'] = np.random.choice(('no', 'yes'), 1, p=[0.55, 0.45])[0]\n",
    "    elif pd.isnull(df['paid_y'][j]):\n",
    "        df.loc[j, 'paid_y'] = np.random.choice(('no', 'yes'), 1, p=[0.95, 0.05])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# еще раз проверяю на наличие пропусков\n",
    "\n",
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "school    181\n",
       "dtype: int64"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#количество записей, у которых признак Medu имеет значение \"4\"\n",
    "df.loc[df['Medu'] == 4, ['school']].count() #'school' просто, чтобы не выдавал все строки с значением 'Medu' == 4, а только одну"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "181 запись, где 'Medu' == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Преобразование всех номинальных признаков в несколько признаков с бинарным значение\n",
    "# У нас есть несколько признаков с бинарными номинальными признаками. Например, пол, школа..\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "cl = list(df.columns.values) # названия всех столбцов\n",
    "\n",
    "#for i, ind in enumerate(cl):\n",
    " #   print(i, ' ', ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin = [0, 1, 3, 4, 5, 15, 16, 17, 18, 19, 20, 21, 22, 36, 37, 38, 39, 40, 41] #индексы столбцов, с бинарными признаками\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "for i in bin:\n",
    "    data_label_encoded = label_encoder.fit_transform(df[cl[i]])\n",
    "    df[cl[i]] = data_label_encoded\n",
    "    \n",
    "#и еще 4 признака с категориальными данными: Mjob (8), Fjob(9), reason(10), guardian_x(11) и guardian_y(32)\n",
    "    \n",
    "new_nom = pd.get_dummies(df.iloc[:,[8, 9, 10, 11, 32]]) #делаем колонки с бинарными признаками\n",
    "df = df.drop(df.columns[[8, 9, 10, 11, 32]], axis=1)    #удаляем старые колонки\n",
    "df = pd.concat([df, new_nom], axis=1)               #добавляем новые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>traveltime_x</th>\n",
       "      <th>studytime_x</th>\n",
       "      <th>...</th>\n",
       "      <th>reason_course</th>\n",
       "      <th>reason_home</th>\n",
       "      <th>reason_other</th>\n",
       "      <th>reason_reputation</th>\n",
       "      <th>guardian_x_father</th>\n",
       "      <th>guardian_x_mother</th>\n",
       "      <th>guardian_x_other</th>\n",
       "      <th>guardian_y_father</th>\n",
       "      <th>guardian_y_mother</th>\n",
       "      <th>guardian_y_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   school  sex  age  address  famsize  Pstatus  Medu  Fedu  traveltime_x  \\\n",
       "0       0    0   18        1        0        0     4     4           2.0   \n",
       "1       0    0   17        1        0        1     1     1           1.0   \n",
       "2       0    0   15        1        1        1     1     1           1.0   \n",
       "3       0    0   15        1        0        1     4     2           1.0   \n",
       "4       0    0   16        1        0        1     3     3           1.0   \n",
       "\n",
       "   studytime_x        ...         reason_course  reason_home  reason_other  \\\n",
       "0          2.0        ...                     1            0             0   \n",
       "1          2.0        ...                     1            0             0   \n",
       "2          2.0        ...                     0            0             1   \n",
       "3          3.0        ...                     0            1             0   \n",
       "4          2.0        ...                     0            1             0   \n",
       "\n",
       "   reason_reputation  guardian_x_father  guardian_x_mother  guardian_x_other  \\\n",
       "0                  0                  0                  1                 0   \n",
       "1                  0                  1                  0                 0   \n",
       "2                  0                  0                  1                 0   \n",
       "3                  0                  0                  1                 0   \n",
       "4                  0                  1                  0                 0   \n",
       "\n",
       "   guardian_y_father  guardian_y_mother  guardian_y_other  \n",
       "0                  0                  1                 0  \n",
       "1                  1                  0                 0  \n",
       "2                  0                  1                 0  \n",
       "3                  0                  1                 0  \n",
       "4                  1                  0                 0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 514,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Классификация (6 баллов)\n",
    "\n",
    "### Предписания\n",
    "- Используйте accuracy как основную меру качества\n",
    "- Классы в задаче несбалансированные. Для корректной кросс-валидации используйте стратифицированный способ разбиения на фолды [Stratified K-fold](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "1. Задайте RANDOM_SEED и случайным образом разделите выборку на обучающую и контрольную в пропорции 80/20. Этот же RANDOM_SEED используйте при кросс-валидации (0.5 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    682\n",
       "dtype: int64"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['alc_x'] == df['alc_y']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# делаю один столбец alc\n",
    "        \n",
    "df['alc'] = 0\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df.loc[i, 'alc'] = df['alc_x'][i]   \n",
    "\n",
    "df = df.drop(['alc_x', 'alc_y'], axis=1)    #удаляем старые колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_SEED = 42                                          \n",
    "\n",
    "X = df[df.columns.difference(['alc'])]                                     \n",
    "y = df['alc']                                         \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=0.4, random_state=RANDOM_SEED) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Random Forest (2 балла)\n",
    "    - В статье описано использование Random Forest для предсказания важности фактором вляющих на потребление алкоголя.\n",
    "    - Повторите эксперимент с использованием [RandomForest](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) и найдите наилучшие параметры с помощью кросс-валидации. (1 балл)\n",
    "    - Изобразите аналогичную таблицу важности признаков для наилучшей настройки метода (значения могут отличаться). (0.5 балла)\n",
    "    - Укажите значение accuracy для пяти наилучших настроек метода на контрольной выборке. (0.5 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 15}"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "param_grid = {'n_estimators':[3,15], \"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [1, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "    \n",
    "clf = GridSearchCV(rfc, param_grid=param_grid, cv=5).fit(X_train, y_train)\n",
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mjob_health</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_health</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_x_other</th>\n",
       "      <td>0.001084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_teacher</th>\n",
       "      <td>0.001330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_y_father</th>\n",
       "      <td>0.001541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pstatus</th>\n",
       "      <td>0.002082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_reputation</th>\n",
       "      <td>0.002285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_at_home</th>\n",
       "      <td>0.002392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romantic_y</th>\n",
       "      <td>0.002909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsup_x</th>\n",
       "      <td>0.003137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_teacher</th>\n",
       "      <td>0.003626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher_y</th>\n",
       "      <td>0.003701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup_x</th>\n",
       "      <td>0.003847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>0.004134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nursery</th>\n",
       "      <td>0.004428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup_y</th>\n",
       "      <td>0.004661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_x_mother</th>\n",
       "      <td>0.005973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_home</th>\n",
       "      <td>0.006034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_course</th>\n",
       "      <td>0.007019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid_x</th>\n",
       "      <td>0.007079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_other</th>\n",
       "      <td>0.007532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_y_other</th>\n",
       "      <td>0.007564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher_x</th>\n",
       "      <td>0.008118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_x</th>\n",
       "      <td>0.008129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_at_home</th>\n",
       "      <td>0.008528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romantic_x</th>\n",
       "      <td>0.008566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activities_y</th>\n",
       "      <td>0.008612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsize</th>\n",
       "      <td>0.008751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_other</th>\n",
       "      <td>0.009199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>0.011351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.011621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveltime_x</th>\n",
       "      <td>0.011787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures_x</th>\n",
       "      <td>0.011938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_services</th>\n",
       "      <td>0.012426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_y_mother</th>\n",
       "      <td>0.013027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveltime_y</th>\n",
       "      <td>0.013346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medu</th>\n",
       "      <td>0.013374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freetime_x</th>\n",
       "      <td>0.015248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_services</th>\n",
       "      <td>0.015467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime_y</th>\n",
       "      <td>0.015883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G3_x</th>\n",
       "      <td>0.016519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fedu</th>\n",
       "      <td>0.019924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famrel_x</th>\n",
       "      <td>0.022958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famrel_y</th>\n",
       "      <td>0.023913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_other</th>\n",
       "      <td>0.024831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G1_x</th>\n",
       "      <td>0.025067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freetime_y</th>\n",
       "      <td>0.025983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime_x</th>\n",
       "      <td>0.026229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures_y</th>\n",
       "      <td>0.029441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G2_y</th>\n",
       "      <td>0.030276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absences_y</th>\n",
       "      <td>0.032842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_y</th>\n",
       "      <td>0.033899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G2_x</th>\n",
       "      <td>0.034334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout_y</th>\n",
       "      <td>0.034807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G3_y</th>\n",
       "      <td>0.041818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.057076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G1_y</th>\n",
       "      <td>0.058923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.061551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout_x</th>\n",
       "      <td>0.070258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   importance\n",
       "Mjob_health          0.000000\n",
       "paid_y               0.000000\n",
       "Fjob_health          0.000000\n",
       "guardian_x_other     0.001084\n",
       "Fjob_teacher         0.001330\n",
       "guardian_y_father    0.001541\n",
       "Pstatus              0.002082\n",
       "reason_reputation    0.002285\n",
       "Fjob_at_home         0.002392\n",
       "romantic_y           0.002909\n",
       "famsup_x             0.003137\n",
       "Mjob_teacher         0.003626\n",
       "higher_y             0.003701\n",
       "schoolsup_x          0.003847\n",
       "internet             0.004134\n",
       "nursery              0.004428\n",
       "schoolsup_y          0.004661\n",
       "guardian_x_mother    0.005973\n",
       "reason_home          0.006034\n",
       "reason_course        0.007019\n",
       "paid_x               0.007079\n",
       "Fjob_other           0.007532\n",
       "guardian_y_other     0.007564\n",
       "higher_x             0.008118\n",
       "health_x             0.008129\n",
       "Mjob_at_home         0.008528\n",
       "romantic_x           0.008566\n",
       "activities_y         0.008612\n",
       "famsize              0.008751\n",
       "Mjob_other           0.009199\n",
       "...                       ...\n",
       "school               0.011351\n",
       "address              0.011621\n",
       "traveltime_x         0.011787\n",
       "failures_x           0.011938\n",
       "Fjob_services        0.012426\n",
       "guardian_y_mother    0.013027\n",
       "traveltime_y         0.013346\n",
       "Medu                 0.013374\n",
       "freetime_x           0.015248\n",
       "Mjob_services        0.015467\n",
       "studytime_y          0.015883\n",
       "G3_x                 0.016519\n",
       "Fedu                 0.019924\n",
       "famrel_x             0.022958\n",
       "famrel_y             0.023913\n",
       "reason_other         0.024831\n",
       "G1_x                 0.025067\n",
       "freetime_y           0.025983\n",
       "studytime_x          0.026229\n",
       "failures_y           0.029441\n",
       "G2_y                 0.030276\n",
       "absences_y           0.032842\n",
       "health_y             0.033899\n",
       "G2_x                 0.034334\n",
       "goout_y              0.034807\n",
       "G3_y                 0.041818\n",
       "age                  0.057076\n",
       "G1_y                 0.058923\n",
       "sex                  0.061551\n",
       "goout_x              0.070258\n",
       "\n",
       "[64 rows x 1 columns]"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# таблица важности признаков\n",
    "\n",
    "fimp = clf.best_estimator_.feature_importances_\n",
    "table = pd.DataFrame(fimp, index=X.columns)\n",
    "table.columns = ['importance']\n",
    "table.sort_values('importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs = clf.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: 0.89976, std: 0.00542, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89976, std: 0.00542, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89976, std: 0.00478, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89731, std: 0.00579, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00773, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89731, std: 0.00632, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89731, std: 0.00579, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89976, std: 0.01191, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89976, std: 0.00478, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89731, std: 0.00579, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.88753, std: 0.01773, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.87286, std: 0.01002, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89242, std: 0.01940, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89976, std: 0.00478, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.87531, std: 0.01668, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90465, std: 0.00502, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.01745, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89487, std: 0.01255, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00773, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89976, std: 0.01635, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.87531, std: 0.02914, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00773, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89731, std: 0.01261, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.89242, std: 0.01176, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90465, std: 0.00502, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.89976, std: 0.01191, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.88020, std: 0.00923, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.01337, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.88998, std: 0.01065, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90465, std: 0.00502, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.88509, std: 0.01211, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90465, std: 0.00502, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89731, std: 0.00965, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'gini', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90465, std: 0.00502, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89976, std: 0.00478, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90465, std: 0.00502, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89976, std: 0.00478, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89731, std: 0.00965, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89976, std: 0.00478, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': 3},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': 3},\n",
       " mean: 0.89731, std: 0.01806, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.88753, std: 0.00907, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89487, std: 0.00569, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89976, std: 0.00478, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 1, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.87531, std: 0.02251, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.89731, std: 0.00579, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89731, std: 0.00632, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90465, std: 0.00920, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89487, std: 0.01452, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89487, std: 0.00569, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89242, std: 0.00888, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89976, std: 0.00478, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 3, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89731, std: 0.01837, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.89976, std: 0.01615, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.88264, std: 0.03482, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90954, std: 0.00995, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.88753, std: 0.01615, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89487, std: 0.01833, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90465, std: 0.01201, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.88264, std: 0.02931, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90465, std: 0.00920, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.88998, std: 0.01126, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 1, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.89976, std: 0.00542, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 3, 'max_depth': None},\n",
       " mean: 0.90220, std: 0.00048, params: {'criterion': 'entropy', 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 10, 'n_estimators': 15, 'max_depth': None}]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_max = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86080586080586086"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. GradientBoosting (2 балла)\n",
    "    - Обучите [GradientBoostingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier)  и найдите для него наилучшие параметры с помощью кросс-валидации. (0.5 балла)\n",
    "    - Изобразите таблицу важности признаков для наилучшей настройки метода. Отличается ли она от таблицы метода RandomForest. Почему? (1 балл)\n",
    "    - Укажите значение accuracy для пяти наилучших настроек метода. (0.5 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9119804400977995 {'min_samples_leaf': 3, 'n_estimators': 30, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "\n",
    "boost_param_grid = {'n_estimators': [10, 30, 100, 300, 1000],\n",
    "                    'max_depth': [2, 3, 4, 5],\n",
    "                    'min_samples_leaf': [1, 2, 3]}\n",
    "\n",
    "boost = GradientBoostingClassifier()\n",
    "boost_clf = GridSearchCV(boost, boost_param_grid, cv=5).fit(X_train, y_train)\n",
    "print(boost_clf.best_score_, boost_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>absences_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_x_mother</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_x_father</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nursery</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activities_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activities_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_x_other</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pstatus</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_services</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_other</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_y_father</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_at_home</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_health</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_teacher</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romantic_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_reputation</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_home</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famrel_x</th>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveltime_x</th>\n",
       "      <td>0.000375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G2_x</th>\n",
       "      <td>0.001825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_course</th>\n",
       "      <td>0.002141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romantic_x</th>\n",
       "      <td>0.002316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher_y</th>\n",
       "      <td>0.002410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_teacher</th>\n",
       "      <td>0.002457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freetime_x</th>\n",
       "      <td>0.002621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_x</th>\n",
       "      <td>0.004278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsup_y</th>\n",
       "      <td>0.004373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_y_mother</th>\n",
       "      <td>0.005318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsize</th>\n",
       "      <td>0.005673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_at_home</th>\n",
       "      <td>0.005871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>0.006025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveltime_y</th>\n",
       "      <td>0.006549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G3_x</th>\n",
       "      <td>0.007136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fedu</th>\n",
       "      <td>0.009007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>0.010003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures_x</th>\n",
       "      <td>0.015270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.015514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime_y</th>\n",
       "      <td>0.016918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G1_x</th>\n",
       "      <td>0.019215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_other</th>\n",
       "      <td>0.019257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_y</th>\n",
       "      <td>0.021213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famrel_y</th>\n",
       "      <td>0.027718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_other</th>\n",
       "      <td>0.029415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_services</th>\n",
       "      <td>0.030613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid_x</th>\n",
       "      <td>0.031749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G2_y</th>\n",
       "      <td>0.036350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G1_y</th>\n",
       "      <td>0.037442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures_y</th>\n",
       "      <td>0.038127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absences_y</th>\n",
       "      <td>0.053560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.055100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medu</th>\n",
       "      <td>0.060486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freetime_y</th>\n",
       "      <td>0.063250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G3_y</th>\n",
       "      <td>0.088090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.116222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout_y</th>\n",
       "      <td>0.132239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   importance\n",
       "absences_x           0.000000\n",
       "guardian_x_mother    0.000000\n",
       "guardian_x_father    0.000000\n",
       "goout_x              0.000000\n",
       "higher_x             0.000000\n",
       "nursery              0.000000\n",
       "activities_y         0.000000\n",
       "activities_x         0.000000\n",
       "paid_y               0.000000\n",
       "guardian_x_other     0.000000\n",
       "Pstatus              0.000000\n",
       "Mjob_services        0.000000\n",
       "Mjob_other           0.000000\n",
       "guardian_y_father    0.000000\n",
       "schoolsup_y          0.000000\n",
       "Mjob_at_home         0.000000\n",
       "Fjob_health          0.000000\n",
       "Fjob_teacher         0.000000\n",
       "romantic_y           0.000000\n",
       "schoolsup_x          0.000000\n",
       "reason_reputation    0.000000\n",
       "reason_home          0.000000\n",
       "famrel_x             0.000119\n",
       "traveltime_x         0.000375\n",
       "G2_x                 0.001825\n",
       "reason_course        0.002141\n",
       "romantic_x           0.002316\n",
       "higher_y             0.002410\n",
       "Mjob_teacher         0.002457\n",
       "freetime_x           0.002621\n",
       "...                       ...\n",
       "health_x             0.004278\n",
       "famsup_y             0.004373\n",
       "guardian_y_mother    0.005318\n",
       "famsize              0.005673\n",
       "Fjob_at_home         0.005871\n",
       "internet             0.006025\n",
       "traveltime_y         0.006549\n",
       "G3_x                 0.007136\n",
       "Fedu                 0.009007\n",
       "school               0.010003\n",
       "failures_x           0.015270\n",
       "address              0.015514\n",
       "studytime_y          0.016918\n",
       "G1_x                 0.019215\n",
       "Fjob_other           0.019257\n",
       "health_y             0.021213\n",
       "famrel_y             0.027718\n",
       "reason_other         0.029415\n",
       "Fjob_services        0.030613\n",
       "paid_x               0.031749\n",
       "G2_y                 0.036350\n",
       "G1_y                 0.037442\n",
       "failures_y           0.038127\n",
       "absences_y           0.053560\n",
       "age                  0.055100\n",
       "Medu                 0.060486\n",
       "freetime_y           0.063250\n",
       "G3_y                 0.088090\n",
       "sex                  0.116222\n",
       "goout_y              0.132239\n",
       "\n",
       "[64 rows x 1 columns]"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# таблица важности признаков\n",
    "\n",
    "boost_fimp = boost_clf.best_estimator_.feature_importances_\n",
    "table = pd.DataFrame(boost_fimp, index=X.columns)\n",
    "table.columns = ['importance']\n",
    "table.sort_values('importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, отличается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86080586080586086"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, boost_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. AdaBoost (1 балл)\n",
    "    - Обучите [AdaBoostClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) и найдите для него наилучшие параметры с помощью кросс-валидации. (0.5 балла)\n",
    "    - Укажите значение accuracy для наилучших настроек метода. (0.5 балла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9070904645476773 {'n_estimators': 30, 'learning_rate': 0.3}\n"
     ]
    }
   ],
   "source": [
    "ada_param_grid = {'n_estimators': [10, 30, 100, 300, 1000],\n",
    "                  'learning_rate': [0.1, 0.3, 1.0, 3.0]}\n",
    "\n",
    "ada = AdaBoostClassifier()\n",
    "ada_clf = GridSearchCV(ada, ada_param_grid, cv=5).fit(X_train, y_train)\n",
    "print(ada_clf.best_score_, ada_clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fedu</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsup_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveltime_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freetime_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_x_father</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_x_mother</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_x_other</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_y_father</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_y_mother</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guardian_y_other</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsize</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nursery</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>paid_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_course</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_home</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_other</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reason_reputation</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romantic_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>school</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>higher_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famrel_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famsup_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Medu</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_at_home</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G3_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G3_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_at_home</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_health</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_other</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traveltime_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_teacher</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pstatus</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absences_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activities_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>failures_x</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activities_y</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mjob_services</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>address</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime_y</th>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>studytime_x</th>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>schoolsup_y</th>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_other</th>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>romantic_x</th>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fjob_teacher</th>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G2_x</th>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>health_y</th>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G2_y</th>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absences_y</th>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freetime_y</th>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>famrel_y</th>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>goout_y</th>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   importance\n",
       "Fedu                 0.000000\n",
       "famsup_x             0.000000\n",
       "traveltime_x         0.000000\n",
       "freetime_x           0.000000\n",
       "goout_x              0.000000\n",
       "guardian_x_father    0.000000\n",
       "guardian_x_mother    0.000000\n",
       "guardian_x_other     0.000000\n",
       "guardian_y_father    0.000000\n",
       "guardian_y_mother    0.000000\n",
       "guardian_y_other     0.000000\n",
       "health_x             0.000000\n",
       "famsize              0.000000\n",
       "higher_x             0.000000\n",
       "internet             0.000000\n",
       "nursery              0.000000\n",
       "paid_x               0.000000\n",
       "paid_y               0.000000\n",
       "reason_course        0.000000\n",
       "reason_home          0.000000\n",
       "reason_other         0.000000\n",
       "reason_reputation    0.000000\n",
       "romantic_y           0.000000\n",
       "school               0.000000\n",
       "schoolsup_x          0.000000\n",
       "higher_y             0.000000\n",
       "famrel_x             0.000000\n",
       "famsup_y             0.000000\n",
       "Medu                 0.000000\n",
       "Fjob_at_home         0.000000\n",
       "...                       ...\n",
       "G3_x                 0.000000\n",
       "G3_y                 0.000000\n",
       "failures_y           0.000000\n",
       "Mjob_at_home         0.000000\n",
       "Mjob_health          0.000000\n",
       "Mjob_other           0.000000\n",
       "traveltime_y         0.000000\n",
       "Mjob_teacher         0.000000\n",
       "Pstatus              0.000000\n",
       "absences_x           0.000000\n",
       "activities_x         0.000000\n",
       "failures_x           0.000000\n",
       "activities_y         0.000000\n",
       "Mjob_services        0.000000\n",
       "address              0.000000\n",
       "studytime_y          0.033333\n",
       "studytime_x          0.033333\n",
       "schoolsup_y          0.033333\n",
       "Fjob_other           0.033333\n",
       "romantic_x           0.033333\n",
       "Fjob_teacher         0.033333\n",
       "G2_x                 0.033333\n",
       "health_y             0.033333\n",
       "G2_y                 0.066667\n",
       "absences_y           0.066667\n",
       "freetime_y           0.066667\n",
       "age                  0.100000\n",
       "famrel_y             0.100000\n",
       "goout_y              0.166667\n",
       "sex                  0.166667\n",
       "\n",
       "[64 rows x 1 columns]"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# таблица важности признаков\n",
    "\n",
    "ada_fimp = ada_clf.best_estimator_.feature_importances_\n",
    "table = pd.DataFrame(ada_fimp, index=X.columns)\n",
    "table.columns = ['importance']\n",
    "table.sort_values('importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85347985347985345"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, ada_clf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Какой из классификаторов оказался лучше? (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Замечания\n",
    "\n",
    "- В работе следует использовать библиотеку scikit-learn версии 0.18 и scipy версии 0.18.1\n",
    "- Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
