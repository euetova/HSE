{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проблема многих алгоримтов построения деревьев в том, что в них не уделяется должного внимания регуляризации. \n",
    "В классическом градиентном бустинге применяется такие меры:\n",
    "- ограничение на структуру дерева: макисмальная глубина (max_depth), минимальное число объектов в листе (min_samples_leaf)\n",
    "- контролирование темпа обучения (learning_rate)\n",
    "- увеличение \"непохожести\" деревьев за счет рандомизации, как в случайном лесе\n",
    "\n",
    "[Xgboost](https://github.com/dmlc/xgboost) использует еще больше параметров для регуляризации базовых деревьев.\n",
    "\n",
    "Целевая функция для оптимизации в Xgboost состоит из двух слагаемых: специфичной пункции потерь и регуляризатора $\\Omega (f_k)$ для каждого из $K$ деревьев, где $f_k$ - прогноз $k$-ого дерева.\n",
    "\n",
    "\n",
    "$$\n",
    "obj(\\theta) = \\sum_{i}^{\\ell} l(y_i - \\hat{y_i}) +  \\sum_{k=1}^{K} \\Omega (f_k)\n",
    "$$\n",
    "\n",
    "Функция потерь зависит от решаемой задачи (Xgboost адаптирован под задачи классификации, регрессии и ранжирования, подробней хорошо описано в [документации](http://xgboost.readthedocs.io/en/latest/model.html) Xgboost), а регуляризатор выглядит следующим образом:\n",
    "\n",
    "$$\n",
    "\\Omega(f) = \\gamma T + \\frac{1}{2} \\lambda \\sum_{j=1}^{T}w_j^2\n",
    "$$\n",
    "\n",
    "Первое слагаемое ($\\gamma T$) штрафует модель за большое число листьев $T$, а второе ($\\frac{1}{2} \\lambda \\sum_{j=1}^{T}w_j^2$) контролирует сумму весов модели в листьях. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Примеры\n",
    "\n",
    "В sklearn доступны алгоритмы AdaBoost и GradientBoosting для задач классификации и регрессии.\n",
    "В качестве примера рассмотрим решение задачи восстановления одномерной регрессии с помощью <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html\">GradientBoostingRegressor</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris, load_boston\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример использования Xgboost для классификации на данных Iris.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  0  0]\n",
      " [ 0  8  0]\n",
      " [ 0  2 11]]\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  1  9]]\n",
      "[[9 0 0]\n",
      " [0 9 1]\n",
      " [0 2 9]]\n",
      "[[12  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  0  7]]\n",
      "[[10  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "kf = KFold(y.shape[0], n_folds=5, shuffle=True, random_state=13)\n",
    "for train_index, test_index in kf:\n",
    "    xgb_model = xgb.XGBClassifier().fit(X[train_index], y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    print(confusion_matrix(actuals, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример восстановления регрессии с Xgboost на данных boston.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.0971394504\n",
      "8.92640647601\n",
      "18.299771839\n",
      "6.73819144817\n",
      "8.47392580766\n"
     ]
    }
   ],
   "source": [
    "boston = load_boston()\n",
    "y = boston['target']\n",
    "X = boston['data']\n",
    "kf = KFold(y.shape[0], n_folds=5, shuffle=True, random_state=17)\n",
    "for train_index, test_index in kf:\n",
    "    xgb_model = xgb.XGBRegressor().fit(X[train_index],y[train_index])\n",
    "    predictions = xgb_model.predict(X[test_index])\n",
    "    actuals = y[test_index]\n",
    "    print(mean_squared_error(actuals, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Простой пример подбора параметров с GridSearchCV.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "0.5984879606490934\n",
      "{'n_estimators': 100, 'max_depth': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  27 out of  27 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "X = boston['data']\n",
    "y = boston['target']\n",
    "\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "xgb_grid = GridSearchCV(xgb_model,\n",
    "                   {'max_depth': [2,4,6],\n",
    "                    'n_estimators': [50,100,200]}, verbose=1)\n",
    "xgb_grid.fit(X,y)\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Пример использования pickle для сохранения обученных моделей.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# must open in binary format to pickle\n",
    "pickle.dump(xgb_grid, open(\"best_boston.pkl\", \"wb\"))\n",
    "clf = pickle.load(open(\"best_boston.pkl\", \"rb\"))\n",
    "print(np.allclose(xgb_grid.predict(X), clf.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ранняя остановка используется для того, чтобы прекратить обучение модели (градиентный спуск), если ошибка за несколько итераций не уменьшилась.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.168889\n",
      "Will train until validation_0-merror hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-merror:0.162222\n",
      "[2]\tvalidation_0-merror:0.151111\n",
      "[3]\tvalidation_0-merror:0.142222\n",
      "[4]\tvalidation_0-merror:0.131111\n",
      "[5]\tvalidation_0-merror:0.128889\n",
      "[6]\tvalidation_0-merror:0.124444\n",
      "[7]\tvalidation_0-merror:0.111111\n",
      "[8]\tvalidation_0-merror:0.113333\n",
      "[9]\tvalidation_0-merror:0.111111\n",
      "[10]\tvalidation_0-merror:0.111111\n",
      "[11]\tvalidation_0-merror:0.111111\n",
      "[12]\tvalidation_0-merror:0.106667\n",
      "[13]\tvalidation_0-merror:0.113333\n",
      "[14]\tvalidation_0-merror:0.108889\n",
      "[15]\tvalidation_0-merror:0.104444\n",
      "[16]\tvalidation_0-merror:0.102222\n",
      "[17]\tvalidation_0-merror:0.102222\n",
      "[18]\tvalidation_0-merror:0.102222\n",
      "[19]\tvalidation_0-merror:0.104444\n",
      "[20]\tvalidation_0-merror:0.104444\n",
      "[21]\tvalidation_0-merror:0.1\n",
      "[22]\tvalidation_0-merror:0.093333\n",
      "[23]\tvalidation_0-merror:0.086667\n",
      "[24]\tvalidation_0-merror:0.086667\n",
      "[25]\tvalidation_0-merror:0.084444\n",
      "[26]\tvalidation_0-merror:0.088889\n",
      "[27]\tvalidation_0-merror:0.086667\n",
      "[28]\tvalidation_0-merror:0.086667\n",
      "[29]\tvalidation_0-merror:0.084444\n",
      "[30]\tvalidation_0-merror:0.082222\n",
      "[31]\tvalidation_0-merror:0.082222\n",
      "[32]\tvalidation_0-merror:0.08\n",
      "[33]\tvalidation_0-merror:0.082222\n",
      "[34]\tvalidation_0-merror:0.08\n",
      "[35]\tvalidation_0-merror:0.077778\n",
      "[36]\tvalidation_0-merror:0.077778\n",
      "[37]\tvalidation_0-merror:0.071111\n",
      "[38]\tvalidation_0-merror:0.071111\n",
      "[39]\tvalidation_0-merror:0.071111\n",
      "[40]\tvalidation_0-merror:0.068889\n",
      "[41]\tvalidation_0-merror:0.068889\n",
      "[42]\tvalidation_0-merror:0.071111\n",
      "[43]\tvalidation_0-merror:0.068889\n",
      "[44]\tvalidation_0-merror:0.068889\n",
      "[45]\tvalidation_0-merror:0.071111\n",
      "[46]\tvalidation_0-merror:0.071111\n",
      "[47]\tvalidation_0-merror:0.071111\n",
      "[48]\tvalidation_0-merror:0.068889\n",
      "[49]\tvalidation_0-merror:0.068889\n",
      "[50]\tvalidation_0-merror:0.066667\n",
      "[51]\tvalidation_0-merror:0.066667\n",
      "[52]\tvalidation_0-merror:0.064444\n",
      "[53]\tvalidation_0-merror:0.062222\n",
      "[54]\tvalidation_0-merror:0.062222\n",
      "[55]\tvalidation_0-merror:0.062222\n",
      "[56]\tvalidation_0-merror:0.066667\n",
      "[57]\tvalidation_0-merror:0.062222\n",
      "[58]\tvalidation_0-merror:0.06\n",
      "[59]\tvalidation_0-merror:0.062222\n",
      "[60]\tvalidation_0-merror:0.06\n",
      "[61]\tvalidation_0-merror:0.062222\n",
      "[62]\tvalidation_0-merror:0.06\n",
      "[63]\tvalidation_0-merror:0.06\n",
      "[64]\tvalidation_0-merror:0.06\n",
      "[65]\tvalidation_0-merror:0.06\n",
      "[66]\tvalidation_0-merror:0.06\n",
      "[67]\tvalidation_0-merror:0.06\n",
      "[68]\tvalidation_0-merror:0.06\n",
      "Stopping. Best iteration:\n",
      "[58]\tvalidation_0-merror:0.06\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=1,\n",
       "       gamma=0, learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, nthread=-1,\n",
       "       objective='multi:softprob', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from  sklearn.cross_validation import train_test_split\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "X = digits['data']\n",
    "y = digits['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(X_train, y_train, early_stopping_rounds=10, eval_metric=\"merror\",\n",
    "        eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полезные ссылки\n",
    "- <a href=\"https://en.wikipedia.org/wiki/Boosting_(machine_learning)\">Boosting</a>\n",
    "- [Gradient boosting](https://en.wikipedia.org/wiki/Gradient_boosting)\n",
    "- [Лекция](http://www.machinelearning.ru/wiki/images/c/cd/Voron-ML-Compositions-slides.pdf) К.В. Воронцова по композиционным методам классификации\n",
    "- <a href=\"https://github.com/dmlc/xgboost\">Xgboost</a>\n",
    "- <a href=\"https://github.com/ChenglongChen/Kaggle_CrowdFlower\">Обзор</a> решения победителя соревнования Kaggle \"CrowdFlower\" по предсказанию релевантности выдачи поисковика товаров. Решение на основе Xgboost"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "2_1_7_regul.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
