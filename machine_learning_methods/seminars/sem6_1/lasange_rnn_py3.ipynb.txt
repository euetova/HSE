{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import os\n",
    "#thanks @keskarnitish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#тут будет текст\n",
    "corpora = \"\"\n",
    "\n",
    "#with open(\"nietzsche.txt\") as fin:\n",
    "with open(\"Call_Him_Lord_by_R_Gordon_Dickson.txt\") as fin:\n",
    "    text = fin.read()#.decode('cp1251')\n",
    "    corpora += text\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#тут будут все уникальные токены (буквы, цифры)\n",
    "tokens = set(corpora)\n",
    "\n",
    "tokens = list(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_to_id = {token:id for id, token in enumerate(tokens)}\n",
    "id_to_token = {id:token for token, id in token_to_id.items()}\n",
    "\n",
    "#Преобразуем всё в токены\n",
    "corpora_ids = list(map(lambda x: token_to_id[x], corpora))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#corpora_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_random_batches(source,n_batches=10, seq_len=20):\n",
    "    \"\"\"Функция, которая выбирает случайные тренировочные примеры из корпуса текста в токенизированном формате.\n",
    "    \n",
    "    source - массив целых чисел - номеров токенов в корпусе (пример - corpora_ids)\n",
    "    n_batches - количество случайных подстрок, которые нужно выбрать\n",
    "    \n",
    "    seq_len - длина одной подстроки без учёта ответа\n",
    "    \n",
    "    \n",
    "    Вернуть нужно кортеж (X,y), где\n",
    "    \n",
    "    X - матрица, в которой каждая строка - подстрока длины [seq_len].\n",
    "    \n",
    "    y - вектор, в котором i-тое число - символ следующий в тексте сразу после i-той строки матрицы X\n",
    "    \n",
    "    Проще всего для этого сначала создать матрицу из строк длины seq_len+1,\n",
    "    а потом отпилить от неё последний столбец в y, а все остальные - в X\n",
    "    \n",
    "    Если делаете иначе - пожалуйста, убедитесь, что в у попадает правильный символ, ибо позже эту ошибку \n",
    "    будет очень тяжело заметить.\n",
    "    \n",
    "    Также убедитесь, что ваша функция не вылезает за край текста (самое начало или конец текста).\n",
    "    \n",
    "    Следующая клетка проверяет часть этих ошибок, но не все.\n",
    "    \"\"\"\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    for i in range(n_batches):\n",
    "        start = np.random.randint(0,len(source) - (seq_len + 1))\n",
    "        stop = start + seq_len\n",
    "        X_batch.append(source[start:stop])\n",
    "        y_batch.append(source[stop:stop + 1])\n",
    "    X_batch = np.array(X_batch)\n",
    "    y_batch = np.array(y_batch)\n",
    "    return X_batch, y_batch\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#длина последоватеьности при обучении (как далеко распространяются градиенты)\n",
    "seq_length = 5\n",
    "\n",
    "# Максимальный модуль градиента\n",
    "grad_clip = 100\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Входные переменные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_sequence = T.matrix('input sequence','int32')\n",
    "target_values = T.ivector('target y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Соберём нейросеть\n",
    "\n",
    "Вам нужно создать нейросеть, которая принимает на вход последовательность из seq_length токенов, обрабатывает их и выдаёт вероятности для seq_len+1-ого токена.\n",
    "\n",
    "Общий шаблон архитектуры такой сети -\n",
    "\n",
    "\n",
    "* Вход\n",
    "* Обработка входа\n",
    "* Рекуррентная нейросеть\n",
    "* Вырезание последнего состояния\n",
    "* Обычная нейросеть\n",
    "* Выходной слой, который предсказывает вероятности весов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_in = lasagne.layers.InputLayer(shape=(None, None),input_var=input_sequence)\n",
    "\n",
    "nn = lasagne.layers.EmbeddingLayer(l_in, input_size=len(tokens), output_size=128)\n",
    "\n",
    "nn = lasagne.layers.LSTMLayer(nn, num_units=512, grad_clipping=grad_clip)\n",
    "\n",
    "nn = lasagne.layers.SliceLayer(nn, -1, 1)\n",
    "\n",
    "l_out = lasagne.layers.DenseLayer(nn, num_units=len(tokens), nonlinearity=lasagne.nonlinearities.softmax)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W, W_in_to_ingate, W_hid_to_ingate, b_ingate, W_in_to_forgetgate, W_hid_to_forgetgate, b_forgetgate, W_in_to_cell, W_hid_to_cell, b_cell, W_in_to_outgate, W_hid_to_outgate, b_outgate, W_cell_to_ingate, W_cell_to_forgetgate, W_cell_to_outgate, W, b]\n"
     ]
    }
   ],
   "source": [
    "# Веса модели\n",
    "weights = lasagne.layers.get_all_params(l_out,trainable=True)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "network_output = lasagne.layers.get_output(l_out)\n",
    "#если вы используете дропаут - не забудьте продублировать всё в режиме deterministic=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = T.nnet.categorical_crossentropy(network_output,target_values).mean()\n",
    "\n",
    "updates = lasagne.updates.rmsprop(loss, weights, learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Компилируем всякое-разное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#обучение\n",
    "train = theano.function([input_sequence, target_values], loss, updates=updates, allow_input_downcast=True)\n",
    "\n",
    "#функция потерь без обучения\n",
    "compute_cost = theano.function([input_sequence, target_values], loss, allow_input_downcast=True)\n",
    "\n",
    "# Вероятности с выхода сети\n",
    "probs = theano.function([input_sequence],network_output,allow_input_downcast=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерируем своего Ницше (или Гордона Диксона)\n",
    "\n",
    "* Для этого последовательно применяем нейронку к своему же выводу.\n",
    "\n",
    "* Генерировать можно по разному -\n",
    " * случайно пропорционально вероятности,\n",
    " * только слова максимальной вероятностью\n",
    " * случайно, пропорционально softmax(probas*alpha), где alpha - \"жадность\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def max_sample_fun(probs):\n",
    "#     print 'probs'\n",
    "#     print probs\n",
    "    return np.argmax(probs) \n",
    "\n",
    "def proportional_sample_fun(probs):\n",
    "    \"\"\"Сгенерировать следующий токен (int32) по предсказанным вероятностям.\n",
    "    \n",
    "    probs - массив вероятностей для каждого токена\n",
    "    \n",
    "    Нужно вернуть одно целове число - выбранный токен - пропорционально вероятностям\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    return np.random.choice(len(probs), 1, p=probs)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The next function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "# The phrase is set using the variable generation_phrase.\n",
    "# The optional input \"N\" is used to set the number of characters of text to predict. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_sample(sample_fun,seed_phrase=None,N=200):\n",
    "    '''\n",
    "    Сгенерировать случайный текст при помощи сети\n",
    "\n",
    "    sample_fun - функция, которая выбирает следующий сгенерированный токен\n",
    "    \n",
    "    seed_phrase - фраза, которую сеть должна продолжить. Если None - фраза выбирается случайно из corpora\n",
    "    \n",
    "    N - размер сгенерированного текста.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    if seed_phrase is None:\n",
    "        start = np.random.randint(0,len(corpora)-seq_length)\n",
    "        seed_phrase = corpora[start:start+seq_length]\n",
    "        print(\"Using random seed:\",seed_phrase)\n",
    "    while len(seed_phrase) < seq_length:\n",
    "        seed_phrase = \" \"+seed_phrase\n",
    "    if len(seed_phrase) > seq_length:\n",
    "        seed_phrase = seed_phrase[len(seed_phrase)-seq_length:]\n",
    "    #assert type(seed_phrase) is unicode\n",
    "        \n",
    "        \n",
    "    sample_ix = []\n",
    "    x = list(map(lambda c: token_to_id.get(c,0), seed_phrase))\n",
    "    x = np.array([x])\n",
    "    \n",
    "    for i in range(N):\n",
    "        # Pick the character that got assigned the highest probability\n",
    "        #print(x)\n",
    "        ix = sample_fun(probs(x).ravel())\n",
    "        # Alternatively, to sample from the distribution instead:\n",
    "        # ix = np.random.choice(np.arange(vocab_size), p=probs(x).ravel())\n",
    "        sample_ix.append(ix)\n",
    "        x[:,0:seq_length-1] = x[:,1:]\n",
    "        x[:,seq_length-1] = 0\n",
    "        x[0,seq_length-1] = ix \n",
    "\n",
    "    random_snippet = seed_phrase + ''.join(id_to_token[ix] for ix in sample_ix)    \n",
    "    print(\"----\\n %s \\n----\" % random_snippet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using random seed:  bent\n",
      "----\n",
      "  bentlHkJJ\n",
      "lkr~YYkl\n",
      "~YY~&kRR\";;;TRnTRJJO\n",
      "H'Lw99tFSCpH\n",
      "WWhn-LHWWnLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWL \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "generate_sample(max_sample_fun,None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели\n",
    "\n",
    "В котором вы можете подёргать параметры или вставить свою генерирующую функцию.\n",
    "Обучение идёт долго, для демонстрации можно прервать раньше, эту модель всё равно можно будет использовать. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: Kyle,\n",
      "----\n",
      " Kyle,K6fS!TF/Dgbim Rm/6b~I*tOfuc\n",
      "HxIEcgS!6ee/yDzLej\n",
      "bu1tshYabm.WK6,ooqp,JuvWdTO?\n",
      "LFnLrg\n",
      "Nytb6Jbpo1K kzjfD-lqT1-Ep*~ty*Ik~g\"mLk?&!CdxsgyIYBS\n",
      "vnRamAwsHvo!jjevH/EkWqb&m&lsjnmdhgK&Jlkep!b9wvGH/wKakc,A'iAU!bkgR \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: ather\n",
      "----\n",
      " atherJMeDDaOrrC'Lre&99ggCph~&dduuxugg\"KKNNhFF*-w99ut-HWWnLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHWLLHW \n",
      "----\n",
      "Epoch 0 average loss = 3.177577724385011\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: t the\n",
      "----\n",
      " t thelo \n",
      "yKytowrr hlled; anoislwoGante dhedioeke\n",
      ",y.i6ridavrtrsatouiranNYeol let altiddwonsat skist thet ongtindyit  idewntoednrke sjisaris\n",
      "tonn ou\n",
      "thena, ro t\n",
      "h'hge klliso, *,egroedyNintk orle\n",
      "nncte\n",
      "nfyle \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: lood \n",
      "----\n",
      " lood oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond oond  \n",
      "----\n",
      "Epoch 1 average loss = 2.6916496104070284\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: osed \n",
      "----\n",
      " osed bew the \n",
      "omf ,\n",
      "one tan. ?pke as wan tune gunee son ske EDnke to n sr, or en pin renn man lot~ an he be we xl le beid owr thes to She  wucin Whe\n",
      "j san~ in ome ke \" he'g hen De can yHe gherus the *nd an \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: e to \n",
      "----\n",
      " e to the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on the s on th \n",
      "----\n",
      "Epoch 2 average loss = 2.571858779994502\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: ce.\" \n",
      "----\n",
      " ce.\" KyA\"es tha leapis- then mesneUwe!s hale beA'd \"\"W'rd,\"PThe.\"\"\"L'kewre he hi be roe'6 and  aaWodeken\n",
      "\"Ller th the har ond onero~ \n",
      "in hid gis \n",
      "sye.\"\"wYP unte,\"\"\"\"A''g and hig Ohe\n",
      "nineirky!fee.\"H\"Ave'd L \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed:  but \n",
      "----\n",
      "  but the be he hin an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an an  \n",
      "----\n",
      "Epoch 3 average loss = 2.5651332084889136\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: t lik\n",
      "----\n",
      " t like\n",
      "tho  las baDgsincing\n",
      "was was and. her\n",
      "wand bo. souO.\".\"\"!of\n",
      "\"Carun. Lorndo\". Go horaugt kand''nd wus Yle ros wenrWlllegserc, forj\n",
      "Ho tho po win zusam and winy. Yloks\n",
      "inl Tlading, wruP, 'ndy wind unc \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: y, an\n",
      "----\n",
      " y, and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and and an \n",
      "----\n",
      "Epoch 4 average loss = 2.4575901986599797\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: e hea\n",
      "----\n",
      " e heand thyoxh ther \n",
      "lugampug dl, wate me?demped andd, ap. Thah ta ad wad youo iybbl?SBt Cet Irog and buck \n",
      "fad inp sit and \"Nnreng mat assighle sa\n",
      "therre.\n",
      "Ther coId demese duYlst accbBe-sasp,\n",
      "\"in be\n",
      "ssoud \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: eeper\n",
      "----\n",
      " eepere the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sad the sa \n",
      "----\n",
      "Epoch 5 average loss = 2.319364547485112\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: e lit\n",
      "----\n",
      " e lit groug,\n",
      "onky counssr ackheH ardog ack let, afr here?\" He spathed whet, Noo\n",
      "me go nhe JcEone Kyleost. An Pfc,wacke\n",
      "tho bes\n",
      "her the grined turhce, \"ol Co the Shuon, hen cadd satf, whh re whyot he berblm \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: \"Maje\n",
      "----\n",
      " \"Maje he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare he pare \n",
      "----\n",
      "Epoch 6 average loss = 2.402585577061138\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: im. \"\n",
      "----\n",
      " im. \"Anter gatherping wi'th noiding bihting thid terring trowhs Bpterlly lem\n",
      "the waax thring iw sKyle\n",
      "sheawh this avoresinga. All\n",
      "meurbs it a hunthy and sotheTding to whi whistt ot te\n",
      "lutd\n",
      "shioning thi ltr \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed:  in t\n",
      "----\n",
      "  in the stint the stint the stint the stint the stint the stint the stint the stint the stint the stint the stint the stint the stint the stint the stint the stint the stint the stint the stint the stint t \n",
      "----\n",
      "Epoch 7 average loss = 2.355385935177188\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: hit\n",
      "t\n",
      "----\n",
      " hit\n",
      "the domeer. . . rest thh rawt ame\n",
      "derse wournd rupKyle9she wrotge siad ormen rere\n",
      "him arund dit Kyles at\n",
      "mohe ard tou on\n",
      "foshere ldee \n",
      "men he singer am leke nen the wrell on here let the hyor Kyle Kyle \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: up to\n",
      "----\n",
      " up to the dince said the dince said the dince said the dince said the dince said the dince said the dince said the dince said the dince said the dince said the dince said the dince said the dince said the  \n",
      "----\n",
      "Epoch 8 average loss = 2.1752499338453113\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: ould \n",
      "----\n",
      " ould stmilht\"s manowaloThinwe to bent, you woaddy but Prowni/uald hit dince lels les mrechathaw towning on was hit.\n",
      "The\n",
      "tu of\n",
      "in 1id? tho him. The in of, paooad f. gutte deking toud blomf\n",
      "no nreaan ead an  \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: fault\n",
      "----\n",
      " faulte to of to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun to doun  \n",
      "----\n",
      "Epoch 9 average loss = 2.1598702059764032\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: ple t\n",
      "----\n",
      " ple ttrive\n",
      "oneredernes he she meap, clootey and tove to wis. ak one. The poll aIad\n",
      "in hicer. Cauld nor. The lim. The ro, 's lan itery. \"Nove misttood an. He\n",
      "kagelee. The Hile foke ine soad to mer. The suth \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: y\n",
      "and\n",
      "----\n",
      " y\n",
      "and an the Prince an the Prince an the Prince an the Prince an the Prince an the Prince an the Prince an the Prince an the Prince an the Prince an the Prince an the Prince an the Prince an the Prince an  \n",
      "----\n",
      "Epoch 10 average loss = 2.1624875394238843\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: away.\n",
      "----\n",
      " away.\n",
      "\"you thealle enen,ad the\n",
      "stere at they un an fatser. Ardy to ferce sling town ithe fing the, sing thoio and kis turte\" onpie in noesss'ild thets at and the leowe Kyle.\"\n",
      "\"Nooke on fasiterKyle ceoa lin \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: cky h\n",
      "----\n",
      " cky hos the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the t \n",
      "----\n",
      "Epoch 11 average loss = 2.1279743558813196\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: llion\n",
      "----\n",
      " llions frewad thtuusss\n",
      "inopu siverpe, meror, antere, thicd u fbrmo\n",
      "to thenwandily laHe,\" be'le  and.\" ve mering truwle.\n",
      "\"Shenotobf merainsonre was frow.\n",
      "\"Fos men\n",
      "er,\n",
      "to tam.ne and thn we stld'aizlowerhe\n",
      "wa \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: d nea\n",
      "----\n",
      " d neace the said.\" \"Fos the said.\" \"Fos the said.\" \"Fos the said.\" \"Fos the said.\" \"Fos the said.\" \"Fos the said.\" \"Fos the said.\" \"Fos the said.\" \"Fos the said.\" \"Fos the said.\" \"Fos the said.\" \"Fos the s \n",
      "----\n",
      "Epoch 12 average loss = 2.164445433582977\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed:  late\n",
      "----\n",
      "  later toung mear young baty. And panrhe hadutu9g at. This\n",
      "Bms, said the saut ging enkapll, as bahlein\" rogaenon to the gand the sad we Jry,\n",
      "logttPr petwron trsise gen he stalliong an taioe noung. The srou \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed:  A bu\n",
      "----\n",
      "  A but said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the  \n",
      "----\n",
      "Epoch 13 average loss = 2.1724536604769127\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: s to \n",
      "----\n",
      " s to leck frough at to the at and dor trias to frive\n",
      "gor~es a abligeslot, gaid\n",
      "cas tat\n",
      "rockion outeD and be. ke\" downgoise\n",
      "dowy from no tike wopero.  Kyles and the don's the wom. \"oust\n",
      "neilesl lippe  ever  \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed:  whil\n",
      "----\n",
      "  while the said.\n",
      "\"I to the said.\n",
      "\"I to the said.\n",
      "\"I to the said.\n",
      "\"I to the said.\n",
      "\"I to the said.\n",
      "\"I to the said.\n",
      "\"I to the said.\n",
      "\"I to the said.\n",
      "\"I to the said.\n",
      "\"I to the said.\n",
      "\"I to the said.\n",
      "\"I to the sa \n",
      "----\n",
      "Epoch 14 average loss = 2.080780147167604\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed: n was\n",
      "----\n",
      " n was ,mere it whe room puly\n",
      "the helly.\n",
      "\"Yiter a her het to mee his his herle6. Thetayyo\n",
      "s. He cere, his id the s ft, he ca wayak lishing dordape\n",
      "pow it you H ard the o.\n",
      "T? the waid af looH's.\n",
      "\"zock himee  \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: ing t\n",
      "----\n",
      " ing the her the her the her the her the her the her the her the her the her the her the her the her the her the her the her the her the her the her the her the her the her the her the her the her the her t \n",
      "----\n",
      "Epoch 15 average loss = 2.070176780240191\n",
      "Генерируем текст в пропорциональном режиме\n",
      "Using random seed:  my l\n",
      "----\n",
      "  my leive the.\"\n",
      "said bay for nerto on't himsidgandle the we Yor allly. I'm'n.\n",
      "\"As man himgong, an to to afNeend.\n",
      "\"Cutly dor on thels\n",
      "the frewneng.\n",
      "She xor standy ren, veand gonfmingon, \"zem\n",
      "and, . The shim \n",
      "----\n",
      "Генерируем текст в жадном режиме (наиболее вероятные буквы)\n",
      "Using random seed: kept \n",
      "----\n",
      " kept the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said the said th \n",
      "----\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-dfe1e1f0f47a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_random_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpora_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mavg_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch {} average loss = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_cost\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatches_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/archy/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/archy/anaconda3/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    949\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    950\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/archy/anaconda3/lib/python3.5/site-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    938\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                         \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                         self, node)\n\u001b[0m\u001b[1;32m    941\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/archy/.theano/compiledir_Linux-4.4--generic-x86_64-with-debian-stretch-sid-x86_64-3.5.2-64/scan_perform/mod.cpp:4193)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/archy/anaconda3/lib/python3.5/site-packages/theano/gof/op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/archy/anaconda3/lib/python3.5/site-packages/theano/tensor/blas.py\u001b[0m in \u001b[0;36mperform\u001b[0;34m(self, node, inp, out)\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m                     \u001b[0mz\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m                     \u001b[0mz\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training ...\")\n",
    "\n",
    "\n",
    "#сколько всего эпох\n",
    "n_epochs=500\n",
    "\n",
    "# раз в сколько эпох печатать примеры \n",
    "batches_per_epoch = 100\n",
    "\n",
    "#сколько цепочек обрабатывать за 1 вызов функции обучения\n",
    "batch_size=10\n",
    "\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    print(\"Генерируем текст в пропорциональном режиме\")\n",
    "    generate_sample(proportional_sample_fun,None)\n",
    "    \n",
    "    print(\"Генерируем текст в жадном режиме (наиболее вероятные буквы)\")\n",
    "    generate_sample(max_sample_fun,None)\n",
    "\n",
    "    avg_cost = 0;\n",
    "    \n",
    "    for _ in range(batches_per_epoch):\n",
    "        \n",
    "        x,y = sample_random_batches(corpora_ids,batch_size,seq_length)\n",
    "        avg_cost += train(x, y[:,0])\n",
    "        \n",
    "    print(\"Epoch {} average loss = {}\".format(epoch, avg_cost / batches_per_epoch))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " wardset cresiin  anter. TheI her   oor .\"\n",
      "The cusn intemhine antel oreanding her let him sidne.\"\n",
      "The ear it you teerd.\n",
      "\"Ter inting hen her hes aive oon ore onside arlime  hing, \n",
      "upere.\"\n",
      "There oreupirge sge.\"Bor oned marked fase.\"\n",
      "Thant pe riding\n",
      "to gut\n",
      "cer, He saidlon.\n",
      "The\n",
      "Prince.\"\n",
      "The ben  Prince shis p \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "seed = \"thousands of years afterwards\"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 300\n",
    "\n",
    "generate_sample(sampling_fun,seed,result_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      " tself orlee lir elling for inne andiggst wwfre soudd or i himse.\n",
      "Then to the reathersemant and ad ouhg .\n",
      "I out dife.\n",
      "The sound\n",
      "yhe lit insid ou himsiI hiwat eace shors.\n",
      "\n",
      "unte.\n",
      "1imwhert eppor hissi ani ce ler ording, then\n",
      "teeat inte.\"\n",
      "ces. \"ce thet dissebling  to alle the ?\"\n",
      "\"Gived andeohe wis is. The en\n",
      " \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "seed = \"which bravely admits this to itself\"\n",
    "sampling_fun = proportional_sample_fun\n",
    "result_length = 300\n",
    "\n",
    "generate_sample(sampling_fun,seed,result_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
